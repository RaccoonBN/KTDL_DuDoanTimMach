# %% [markdown]
# # Modeling: ÄÃ¡nh giÃ¡ nguy cÆ¡ máº¯c bá»‡nh tim báº±ng AI
# * **NhÃ³m:** 3
# 

# %% [markdown]
# ## **Má»¥c lá»¥c**<a is='Contents'></a>  
# * [Giá»›i thiá»‡u](#Introduction)  
# * [Táº­p dá»¯ liá»‡u](#Dataset)  
# * [CÃ i Ä‘áº·t vÃ  chuáº©n bá»‹](#Setup_and_preliminaries)  
#   * [Nháº­p thÆ° viá»‡n](#Import_libraries)  
#   * [CÃ¡c hÃ m cáº§n thiáº¿t](#Necessary_Functions)  
# * [Nháº­p táº­p dá»¯ liá»‡u](#Importing_dataset)  
# * [XÃ¡c thá»±c táº­p dá»¯ liá»‡u](#Validating_the_dataset)  
# * [CÃ¡c Ä‘áº·c trÆ°ng liÃªn quan Ä‘áº¿n bá»‡nh tim](#Heart_Disease_related_features)  
# * [Chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u cá»§a Ä‘áº·c trÆ°ng](#Converting_features_data_type)  
# * [Bá»‡nh tim: Biáº¿n má»¥c tiÃªu](#Heart_Disease_Target_Variable)  
# * [Lá»±a chá»n Ä‘áº·c trÆ°ng](#Features_Selection)  
# * [MÃ£ hÃ³a danh má»¥c báº±ng CatBoost](#Categorical_Encoding_with_Catboost)  
# * [Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra](#Split_data_into_training_and_testing_sets)  
# * [Chuáº©n hÃ³a Ä‘áº·c trÆ°ng cho há»“i quy Logistic](#Scale_features_for_Logistic_Regression)  
# * [MÃ´ hÃ¬nh cÆ¡ báº£n](#Baseline_Modeling)  
#   * [So sÃ¡nh cÃ¡c chá»‰ sá»‘ theo tá»«ng lá»›p](#class_specific_level_Metrics_Comparison)  
#   * [TÃ³m táº¯t cÃ¡c chá»‰ sá»‘ theo tá»«ng lá»›p](#Class_specific_level_Metrics_Summary)  
# * [Lá»±a chá»n mÃ´ hÃ¬nh](#Model_Selection)  
# * [Tá»‘i Æ°u hÃ³a tham sá»‘ báº±ng Optuna](#Hyperparameter_Tuning_using_Optuna)  
# * [Huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»‘t nháº¥t (Ä‘Ã£ tinh chá»‰nh)](#Fitting_Best_Model_tuned)  
# * [Táº§m quan trá»ng cá»§a Ä‘áº·c trÆ°ng trong mÃ´ hÃ¬nh tá»‘t nháº¥t báº±ng SHAP](#Tuned_Best_Model_Features_Importance_using_SHAP)  
# * [LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng](#Saving_Final_Model)  

# %% [markdown]
# ## **Giá»›i thiá»‡u**<a id='Introduction'></a>  
# [Quay láº¡i Má»¥c lá»¥c](#Contents)  
# 
# Trong notebook nÃ y, chÃºng ta sáº½ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ nhiá»u mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ phÃ¢n loáº¡i bá»‡nh tim, bao gá»“m:  
# 
# * Há»“i quy Logistic (Logistic Regression)  
# * Rá»«ng ngáº«u nhiÃªn (Random Forest)  
# * XGBoost  
# * LightGBM  
# * Balanced Bagging  
# * Easy Ensemble  
# * Balanced Random Forest  
# * Balanced Bagging (LightGBM): Sá»­ dá»¥ng Balanced Bagging lÃ m Wrapper vÃ  LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ  
# * Easy Ensemble (LightGBM): Sá»­ dá»¥ng Easy Ensemble lÃ m Wrapper vÃ  LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ  
# 
# Má»¥c tiÃªu cá»§a chÃºng ta lÃ  dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c nguy cÆ¡ máº¯c bá»‡nh tim báº±ng cÃ¡c mÃ´ hÃ¬nh nÃ y. ChÃºng ta sáº½ Ã¡p dá»¥ng tá»‘i Æ°u hÃ³a tham sá»‘ báº±ng `Optuna` Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a tá»«ng mÃ´ hÃ¬nh. NgoÃ i ra, chÃºng ta sáº½ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n `BalancedRandomForestClassifier`, `BalancedBaggingClassifier` vÃ  `EasyEnsembleClassifier` tá»« thÆ° viá»‡n `imbalanced-learn` Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» máº¥t cÃ¢n báº±ng lá»›p. Nhá»¯ng bá»™ phÃ¢n loáº¡i nÃ y sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p láº¥y máº«u bootstrap Ä‘á»ƒ cÃ¢n báº±ng táº­p dá»¯ liá»‡u, giÃºp cáº£i thiá»‡n kháº£ nÄƒng phÃ¢n loáº¡i cÃ¡c lá»›p thiá»ƒu sá»‘.  
# 
# Báº±ng cÃ¡ch táº­p trung vÃ o dá»¯ liá»‡u bá»‹ Ä‘Ã¡nh giÃ¡ tháº¥p, phÆ°Æ¡ng phÃ¡p nÃ y giÃºp nÃ¢ng cao hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh, lÃ m cho nÃ³ Ä‘áº·c biá»‡t phÃ¹ há»£p vá»›i cÃ¡c táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nhÆ° dá»± Ä‘oÃ¡n bá»‡nh tim. ThÃ´ng qua cÃ¡ch tiáº¿p cáº­n toÃ n diá»‡n nÃ y, chÃºng ta hÆ°á»›ng Ä‘áº¿n viá»‡c phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh Ä‘Ã¡ng tin cáº­y vÃ  hiá»‡u quáº£ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ nguy cÆ¡ máº¯c bá»‡nh tim, gÃ³p pháº§n cáº£i thiá»‡n káº¿t quáº£ sá»©c khá»e cho cá»™ng Ä‘á»“ng.

# %% [markdown]
# ## **Táº­p dá»¯ liá»‡u**<a id='Dataset'></a>  
# [Quay láº¡i Má»¥c lá»¥c](#Contents)  
# 
# Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong notebook nÃ y lÃ  káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u toÃ n diá»‡n. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u lÃ  má»™t bÆ°á»›c quan trá»ng trong quy trÃ¬nh khoa há»c dá»¯ liá»‡u, bao gá»“m viá»‡c chuyá»ƒn Ä‘á»•i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u thÃ´ thÃ nh Ä‘á»‹nh dáº¡ng phÃ¹ há»£p hÆ¡n cho phÃ¢n tÃ­ch. CÃ¡c nhiá»‡m vá»¥ chÃ­nh Ä‘Æ°á»£c thá»±c hiá»‡n trong quÃ¡ trÃ¬nh nÃ y bao gá»“m:  
# 
# * Xá»­ lÃ½ dá»¯ liá»‡u bá»‹ thiáº¿u  
# * Ãnh xáº¡ dá»¯ liá»‡u  
# * LÃ m sáº¡ch dá»¯ liá»‡u  
# * Ká»¹ thuáº­t Ä‘áº·c trÆ°ng (Feature engineering)  
# 
# Nhá»¯ng bÆ°á»›c nÃ y Ä‘áº£m báº£o ráº±ng táº­p dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n bá»‹ tá»‘t Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh, giÃºp táº¡o ra cÃ¡c mÃ´ hÃ¬nh Ä‘Ã¡ng tin cáº­y vÃ  chÃ­nh xÃ¡c trong dá»± Ä‘oÃ¡n nguy cÆ¡ máº¯c bá»‡nh tim.

# %% [markdown]
# ## **Thiáº¿t láº­p vÃ  Chuáº©n bá»‹**<a id='Setup_and_preliminaries'></a>  
# [Quay láº¡i Má»¥c lá»¥c](#Contents)

# %% [markdown]
# ### **Import libraries**<a id='Import_libraries'></a>
# [Contents](#Contents)

# %%
# Nháº­p cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
import scipy.stats as stats
from scipy.stats import gamma, linregress
from bs4 import BeautifulSoup
import re

# MÃ´ hÃ¬nh há»c mÃ¡y
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
import category_encoders as ce 
from sklearn.feature_selection import mutual_info_classif
from sklearn.model_selection import train_test_split

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import accuracy_score, classification_report
import shap

# Tinh chá»‰nh siÃªu tham sá»‘
import optuna

# Xá»­ lÃ½ máº¥t cÃ¢n báº±ng lá»›p
from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, EasyEnsembleClassifier
from imblearn.metrics import classification_report_imbalanced

# Thiáº¿t láº­p hiá»ƒn thá»‹ cho notebook:
pd.set_option('display.max_columns', None)  # Hiá»ƒn thá»‹ táº¥t cáº£ cÃ¡c cá»™t
pd.set_option('display.max_rows', None)  # Hiá»ƒn thá»‹ táº¥t cáº£ cÃ¡c hÃ ng

# Äá»‹nh dáº¡ng sá»‘ thá»±c vá»›i 2 chá»¯ sá»‘ tháº­p phÃ¢n: ChÃºng ta cÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ i Ä‘áº·t nÃ y náº¿u cáº§n thiáº¿t cho cÃ¡c cÃ¢u tráº£ lá»i cá»¥ thá»ƒ trong bÃ i táº­p nÃ y.
# pd.set_option('float_format', '{:.2f}'.format)

# Táº¯t cáº£nh bÃ¡o khÃ´ng cáº§n thiáº¿t
import warnings
warnings.filterwarnings('ignore', category=FutureWarning, module='xgboost')
warnings.filterwarnings('ignore', category=FutureWarning, module='imblearn')

# %% [markdown]
# ### **Necessary  functions**<a id='Necessary_Functions'></a>
# [Contents](#Contents)

# %%
def summarize_df(df):
    """
    Táº¡o má»™t DataFrame tÃ³m táº¯t cho DataFrame Ä‘áº§u vÃ o.

    Tham sá»‘:
    df (pd.DataFrame): DataFrame cáº§n Ä‘Æ°á»£c tÃ³m táº¯t.

    Tráº£ vá»:
    Má»™t DataFrame chá»©a cÃ¡c thÃ´ng tin sau:
        - 'unique_count': Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ duy nháº¥t trong má»—i cá»™t.
        - 'data_types': Kiá»ƒu dá»¯ liá»‡u cá»§a má»—i cá»™t.
        - 'missing_counts': Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ bá»‹ thiáº¿u (NaN) trong má»—i cá»™t.
        - 'missing_percentage': Tá»· lá»‡ pháº§n trÄƒm giÃ¡ trá»‹ bá»‹ thiáº¿u trong má»—i cá»™t.
    """
    # Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ duy nháº¥t cho má»—i cá»™t:
    unique_counts = df.nunique()    
    # Kiá»ƒu dá»¯ liá»‡u cá»§a má»—i cá»™t:
    data_types = df.dtypes    
    # Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ bá»‹ thiáº¿u (NaN) trong má»—i cá»™t:
    missing_counts = df.isnull().sum()    
    # Tá»· lá»‡ pháº§n trÄƒm giÃ¡ trá»‹ bá»‹ thiáº¿u trong má»—i cá»™t:
    missing_percentage = 100 * df.isnull().mean()    
    # GhÃ©p cÃ¡c thÃ´ng tin trÃªn vÃ o má»™t DataFrame:
    summary_df = pd.concat([unique_counts, data_types, missing_counts, missing_percentage], axis=1)    
    # Äá»•i tÃªn cá»™t cho dá»… Ä‘á»c:
    summary_df.columns = ['unique_count', 'data_types', 'missing_counts', 'missing_percentage']   
    # Tráº£ vá» DataFrame tÃ³m táº¯t:
    return summary_df

#-----------------------------------------------------------------------------------------------------------------#
# HÃ m lÃ m sáº¡ch vÃ  Ä‘á»‹nh dáº¡ng nhÃ£n
def clean_label(label):
    # Thay tháº¿ báº¥t ká»³ kÃ½ tá»± nÃ o khÃ´ng pháº£i chá»¯ cÃ¡i hoáº·c sá»‘ báº±ng chuá»—i rá»—ng
    label = re.sub(r'[^a-zA-Z0-9\s]', '', label)
    # Thay tháº¿ dáº¥u cÃ¡ch báº±ng dáº¥u gáº¡ch dÆ°á»›i
    label = re.sub(r'\s+', '_', label)
    return label

#-----------------------------------------------------------------------------------------------------------------#
def value_counts_with_percentage(df, column_name):
    """
    TÃ­nh toÃ¡n sá»‘ láº§n xuáº¥t hiá»‡n vÃ  pháº§n trÄƒm cá»§a tá»«ng giÃ¡ trá»‹ trong má»™t cá»™t.

    Tham sá»‘:
    df (pd.DataFrame): DataFrame chá»©a dá»¯ liá»‡u.
    column_name (str): TÃªn cá»™t cáº§n phÃ¢n tÃ­ch.

    Tráº£ vá»:
    Má»™t DataFrame vá»›i hai cá»™t:
        - 'Count': Sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»«ng giÃ¡ trá»‹.
        - 'Percentage': Tá»· lá»‡ pháº§n trÄƒm cá»§a tá»«ng giÃ¡ trá»‹.
    """
    # TÃ­nh sá»‘ láº§n xuáº¥t hiá»‡n
    counts = df[column_name].value_counts(dropna=False)
    
    # TÃ­nh pháº§n trÄƒm
    percentages = df[column_name].value_counts(dropna=False, normalize=True) * 100
    
    # Káº¿t há»£p sá»‘ láº§n xuáº¥t hiá»‡n vÃ  pháº§n trÄƒm vÃ o má»™t DataFrame
    result = pd.DataFrame({
        'Count': counts,
        'Percentage': percentages
    })
    
    return result

#-----------------------------------------------------------------------------------------------------------------#

def plot_heart_disease_distribution(df, target):
    """
    Váº½ biá»ƒu Ä‘á»“ thanh ngang xáº¿p chá»“ng Ä‘á»ƒ thá»ƒ hiá»‡n phÃ¢n bá»‘ cá»§a biáº¿n má»¥c tiÃªu 'Heart Disease'.
    
    Tham sá»‘:
    df (pd.DataFrame): DataFrame chá»©a dá»¯ liá»‡u.
    target (str): TÃªn cá»™t má»¥c tiÃªu.
    """
    # Táº¡o báº£ng crosstab
    crosstab = pd.crosstab(df[target], df[target])

    # Váº½ biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(16, 6))  # TÄƒng chiá»u rá»™ng cá»§a hÃ¬nh váº½
    crosstab.plot(kind='barh', stacked=True, color=['green', 'red'], ax=ax)
    ax.set_title(f'PhÃ¢n bá»‘ {target}')
    ax.set_xlabel('Sá»‘ lÆ°á»£ng')
    ax.set_ylabel(target)
    ax.grid(True, axis='x')
    ax.set_axisbelow(True)  # Äáº·t lÆ°á»›i phÃ­a sau cÃ¡c thanh

    # ThÃªm nhÃ£n bÃªn ngoÃ i cÃ¡c thanh
    for i in range(len(crosstab)):
        total = sum(crosstab.iloc[i])
        label_no = f"KhÃ´ng ({crosstab.iloc[i, 0] / 1000:.1f}K)"
        label_yes = f"CÃ³ ({crosstab.iloc[i, 1] / 1000:.1f}K)"
        ax.text(total + 5000, i, f'{label_no}, {label_yes}', ha='left', va='center', color='black')

    # Äiá»u chá»‰nh giá»›i háº¡n Ä‘á»ƒ Ä‘áº£m báº£o nhÃ£n vá»«a vá»›i biá»ƒu Ä‘á»“
    ax.set_xlim(right=ax.get_xlim()[1] + 100000)

    # Di chuyá»ƒn chÃº thÃ­ch ra ngoÃ i khu vá»±c biá»ƒu Ä‘á»“
    ax.legend(title=target, loc='center left', bbox_to_anchor=(1, 0.5))
    
    # Äáº£m báº£o nhÃ£n vÃ  khu vá»±c váº½ biá»ƒu Ä‘á»“ phÃ¹ há»£p vá»›i kÃ­ch thÆ°á»›c hÃ¬nh váº½
    plt.tight_layout(rect=[0, 0, 0.85, 1])
    plt.show()

# %% [markdown]
# ## **Importing dataset**<a id='Importing_dataset'></a>
# [Contents](#Contents)

# %%
df = pd.read_csv('brfss2022_data_wrangling_output.csv')

# %% [markdown]
# ## **XÃ¡c thá»±c Táº­p dá»¯ liá»‡u**<a id='Validating_the_dataset'></a>  
# [Contents](#Contents)

# %%

df.head()

# %%
#BÃ¢y giá», hÃ£y xem kÃ­ch thÆ°á»›c cá»§a DataFrame:
shape = df.shape
print("Sá»‘ hÃ ng:", shape[0], "\nSá»‘ cá»™t:", shape[1])

# %% [markdown]
# ## **CÃ¡c Ä‘áº·c Ä‘iá»ƒm liÃªn quan Ä‘áº¿n bá»‡nh tim**<a id='Heart_Disease_related_features'></a>  
# [Contents](#Contents)  
# 
# Sau nhiá»u ngÃ y nghiÃªn cá»©u vÃ  phÃ¢n tÃ­ch cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a táº­p dá»¯ liá»‡u, chÃºng tÃ´i Ä‘Ã£ xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c Ä‘iá»ƒm chÃ­nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ bá»‡nh tim nhÆ° sau:  
# 
# ### **Biáº¿n má»¥c tiÃªu (Biáº¿n phá»¥ thuá»™c):**  
# - **Heart_disease** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n máº¯c bá»‡nh Ä‘au tháº¯t ngá»±c hoáº·c bá»‡nh tim máº¡ch vÃ nh*): "Ever_Diagnosed_with_Angina_or_Coronary_Heart_Disease"  
# 
# ### **NhÃ¢n kháº©u há»c:**  
# - **Gender** (*Giá»›i tÃ­nh*): Are_you_male_or_female  
# - **Race** (*Chá»§ng tá»™c*): Computed_race_groups_used_for_internet_prevalence_tables  
# - **Age** (*Tuá»•i*): Imputed_Age_value_collapsed_above_80  
# 
# ### **Tiá»n sá»­ bá»‡nh:**  
# - **General_Health** (*TÃ¬nh tráº¡ng sá»©c khá»e tá»•ng quÃ¡t*)  
# - **Have_Personal_Health_Care_Provider** (*CÃ³ nhÃ  cung cáº¥p dá»‹ch vá»¥ chÄƒm sÃ³c sá»©c khá»e cÃ¡ nhÃ¢n*)  
# - **Could_Not_Afford_To_See_Doctor** (*KhÃ´ng Ä‘á»§ kháº£ nÄƒng tÃ i chÃ­nh Ä‘á»ƒ Ä‘i khÃ¡m bÃ¡c sÄ©*)  
# - **Length_of_time_since_last_routine_checkup** (*Khoáº£ng thá»i gian tá»« láº§n kiá»ƒm tra sá»©c khá»e Ä‘á»‹nh ká»³ gáº§n nháº¥t*)  
# - **Ever_Diagnosed_with_Heart_Attack** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n bá»‹ Ä‘au tim*)  
# - **Ever_Diagnosed_with_a_Stroke** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n bá»‹ Ä‘á»™t quá»µ*)  
# - **Ever_told_you_had_a_depressive_disorder** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n máº¯c rá»‘i loáº¡n tráº§m cáº£m*)  
# - **Ever_told_you_have_kidney_disease** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n máº¯c bá»‡nh tháº­n*)  
# - **Ever_told_you_had_diabetes** (*Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n máº¯c bá»‡nh tiá»ƒu Ä‘Æ°á»ng*)  
# - **Reported_Weight_in_Pounds** (*CÃ¢n náº·ng bÃ¡o cÃ¡o theo Ä‘Æ¡n vá»‹ pound*)  
# - **Reported_Height_in_Feet_and_Inches** (*Chiá»u cao bÃ¡o cÃ¡o theo Ä‘Æ¡n vá»‹ feet vÃ  inch*)  
# - **Computed_body_mass_index_categories** (*Chá»‰ sá»‘ khá»‘i cÆ¡ thá»ƒ (BMI) tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# - **Difficulty_Walking_or_Climbing_Stairs** (*Gáº·p khÃ³ khÄƒn khi Ä‘i bá»™ hoáº·c leo cáº§u thang*)  
# - **Computed_Physical_Health_Status** (*TÃ¬nh tráº¡ng sá»©c khá»e thá»ƒ cháº¥t tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# - **Computed_Mental_Health_Status** (*TÃ¬nh tráº¡ng sá»©c khá»e tÃ¢m tháº§n tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# - **Computed_Asthma_Status** (*TÃ¬nh tráº¡ng hen suyá»…n tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# 
# ### **Lá»‘i sá»‘ng:**  
# - **Leisure_Time_Physical_Activity_Calculated_Variable** (*Má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng thá»ƒ cháº¥t trong thá»i gian ráº£nh*)  
# - **Smoked_at_Least_100_Cigarettes** (*Tá»«ng hÃºt Ã­t nháº¥t 100 Ä‘iáº¿u thuá»‘c*)  
# - **Computed_Smoking_Status** (*TÃ¬nh tráº¡ng hÃºt thuá»‘c tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# - **Binge_Drinking_Calculated_Variable** (*TÃ¬nh tráº¡ng uá»‘ng rÆ°á»£u bia quÃ¡ má»©c*)  
# - **Computed_number_of_drinks_of_alcohol_beverages_per_week** (*Sá»‘ lÆ°á»£ng Ä‘á»“ uá»‘ng cÃ³ cá»“n tiÃªu thá»¥ má»—i tuáº§n tÃ­nh toÃ¡n Ä‘Æ°á»£c*)  
# - **Exercise_in_Past_30_Days** (*CÃ³ táº­p thá»ƒ dá»¥c trong 30 ngÃ y qua khÃ´ng*)  
# - **How_Much_Time_Do_You_Sleep** (*Báº¡n ngá»§ bao nhiÃªu giá» má»—i ngÃ y*)

# %%
#HÃ£y cháº¡y Ä‘oáº¡n mÃ£ dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ kiá»ƒm tra láº¡i tá»«ng Ä‘áº·c Ä‘iá»ƒm, bao gá»“m sá»‘ lÆ°á»£ng vÃ  tá»· lá»‡ dá»¯ liá»‡u bá»‹ thiáº¿u, sá»‘ giÃ¡ trá»‹ duy nháº¥t, vÃ  kiá»ƒu dá»¯ liá»‡u:
summarize_df(df)

# %% [markdown]
# ## **Chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u cá»§a cÃ¡c Ä‘áº·c Ä‘iá»ƒm**<a id='Converting_features_data_type'></a>  
# [Contents](#Contents)  
# 
# Trong pandas, kiá»ƒu dá»¯ liá»‡u `object` Ä‘Æ°á»£c sá»­ dá»¥ng cho dá»¯ liá»‡u dáº¡ng vÄƒn báº£n hoáº·c dá»¯ liá»‡u há»—n há»£p. Khi má»™t cá»™t chá»©a dá»¯ liá»‡u phÃ¢n loáº¡i (categorical data), viá»‡c chuyá»ƒn Ä‘á»•i nÃ³ sang kiá»ƒu dá»¯ liá»‡u danh má»¥c (`category`) cÃ³ thá»ƒ mang láº¡i nhiá»u lá»£i Ã­ch.  
# 
# ### **Lá»£i Ã­ch cá»§a viá»‡c chuyá»ƒn Ä‘á»•i sang kiá»ƒu dá»¯ liá»‡u danh má»¥c:**  
# - **Tiáº¿t kiá»‡m bá»™ nhá»›:** Kiá»ƒu dá»¯ liá»‡u danh má»¥c giÃºp sá»­ dá»¥ng bá»™ nhá»› hiá»‡u quáº£ hÆ¡n. Thay vÃ¬ lÆ°u tá»«ng chuá»—i riÃªng biá»‡t, pandas chá»‰ lÆ°u cÃ¡c danh má»¥c vÃ  sá»­ dá»¥ng mÃ£ sá»‘ nguyÃªn Ä‘á»ƒ Ä‘áº¡i diá»‡n cho cÃ¡c giÃ¡ trá»‹.  
# - **Cáº£i thiá»‡n hiá»‡u suáº¥t:** CÃ¡c thao tÃ¡c trÃªn dá»¯ liá»‡u danh má»¥c cÃ³ thá»ƒ nhanh hÆ¡n vÃ¬ pandas cÃ³ thá»ƒ sá»­ dá»¥ng mÃ£ sá»‘ nguyÃªn bÃªn dÆ°á»›i.  
# - **Ã nghÄ©a rÃµ rÃ ng hÆ¡n:** Viá»‡c chuyá»ƒn Ä‘á»•i sang kiá»ƒu danh má»¥c giÃºp lÃ m rÃµ báº£n cháº¥t phÃ¢n loáº¡i cá»§a dá»¯ liá»‡u, cáº£i thiá»‡n kháº£ nÄƒng Ä‘á»c mÃ£ vÃ  giáº£m nguy cÆ¡ xá»­ lÃ½ nháº§m dá»¯ liá»‡u phÃ¢n loáº¡i nhÆ° dá»¯ liá»‡u liÃªn tá»¥c.

# %%
# Chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t sang kiá»ƒu danh má»¥c
categorical_columns = df.columns  # giáº£ sá»­ táº¥t cáº£ cÃ¡c cá»™t cáº§n chuyá»ƒn sang kiá»ƒu danh má»¥c
df[categorical_columns] = df[categorical_columns].astype('category')

summarize_df(df)

# %% [markdown]
# Tá»‘t! Giá» táº¥t cáº£ cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn sang kiá»ƒu dá»¯ liá»‡u danh má»¥c, hÃ£y chuyá»ƒn sang bÆ°á»›c tiáº¿p theo. ğŸš€

# %% [markdown]
# ## **Bá»‡nh tim: Biáº¿n má»¥c tiÃªu**<a id='Heart_Disease_Target_Variable'></a>  
# [Danh má»¥c ná»™i dung](#Contents)

# %%
# ÄÆ°á»£c rá»“i, bÃ¢y giá» hÃ£y xem phÃ¢n bá»‘ cá»§a bá»‡nh tim:  
plot_heart_disease_distribution(df, 'heart_disease')

# %% [markdown]
# ### **PhÃ¢n tÃ­ch phÃ¢n bá»‘**  
# * CÃ³ sá»± máº¥t cÃ¢n báº±ng Ä‘Ã¡ng ká»ƒ giá»¯a hai nhÃ³m.  
# * Pháº§n lá»›n sá»‘ ngÆ°á»i khÃ´ng máº¯c bá»‡nh tim (`418.3K`), trong khi sá»‘ ngÆ°á»i máº¯c bá»‡nh tim Ã­t hÆ¡n nhiá»u (`26.8K`).  
# * Sá»± máº¥t cÃ¢n báº±ng nÃ y cÃ³ thá»ƒ quan sÃ¡t rÃµ trong biá»ƒu Ä‘á»“, vá»›i thanh mÃ u xanh lÃ¡ cÃ¢y dÃ i hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i thanh mÃ u Ä‘á».  
# 
# ### **Váº¥n Ä‘á» máº¥t cÃ¢n báº±ng**  
# * **ThiÃªn vá»‹ mÃ´ hÃ¬nh:** Khi huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i trÃªn táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng nÃ y, mÃ´ hÃ¬nh cÃ³ thá»ƒ bá»‹ thiÃªn vá»‹ vÃ  dá»± Ä‘oÃ¡n nhÃ³m Ä‘a sá»‘ (khÃ´ng máº¯c bá»‡nh tim) thÆ°á»ng xuyÃªn hÆ¡n do nhÃ³m nÃ y xuáº¥t hiá»‡n nhiá»u hÆ¡n trong dá»¯ liá»‡u huáº¥n luyá»‡n.  
# * **Chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t:** CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ phá»• biáº¿n nhÆ° Ä‘á»™ chÃ­nh xÃ¡c cÃ³ thá»ƒ gÃ¢y hiá»ƒu láº§m trÃªn táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng. VÃ­ dá»¥, má»™t mÃ´ hÃ¬nh luÃ´n dá»± Ä‘oÃ¡n "KhÃ´ng máº¯c bá»‡nh tim" cÃ³ thá»ƒ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao vÃ¬ nhÃ³m Ä‘a sá»‘ Ä‘Æ°á»£c Ä‘áº¡i diá»‡n tá»‘t. Tuy nhiÃªn, mÃ´ hÃ¬nh nÃ y sáº½ tháº¥t báº¡i trong viá»‡c xÃ¡c Ä‘á»‹nh nhá»¯ng ngÆ°á»i máº¯c bá»‡nh tim, Ä‘iá»u nÃ y ráº¥t quan trá»ng trong cÃ¡c á»©ng dá»¥ng y táº¿.  
# * **Recall vÃ  Precision:** CÃ¡c chá»‰ sá»‘ nhÆ° recall (Ä‘á»™ nháº¡y) vÃ  precision (Ä‘á»™ chÃ­nh xÃ¡c) cÃ³ Ã½ nghÄ©a hÆ¡n trong bá»‘i cáº£nh nÃ y. Recall Ä‘o lÆ°á»ng kháº£ nÄƒng nháº­n diá»‡n cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh thá»±c sá»± (máº¯c bá»‡nh tim), trong khi precision Ä‘o lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c dá»± Ä‘oÃ¡n dÆ°Æ¡ng tÃ­nh. Trong táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng, má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ cÃ³ recall tháº¥p Ä‘á»‘i vá»›i nhÃ³m thiá»ƒu sá»‘ (máº¯c bá»‡nh tim) ngay cáº£ khi Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ cao.  
# 
# ### **Chiáº¿n lÆ°á»£c giáº£i quyáº¿t máº¥t cÃ¢n báº±ng**  
# CÃ¡c mÃ´ hÃ¬nh nhÆ° `BalancedRandomForestClassifier`, `BalancedBaggingClassifier` hoáº·c `EasyEnsembleClassifier` trong thÆ° viá»‡n `imbalanced-learn` giÃºp xá»­ lÃ½ hiá»‡u quáº£ váº¥n Ä‘á» máº¥t cÃ¢n báº±ng báº±ng cÃ¡ch sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p láº¥y máº«u bootstrap Ä‘á»ƒ cÃ¢n báº±ng táº­p dá»¯ liá»‡u. Äiá»u nÃ y giÃºp cáº£i thiá»‡n kháº£ nÄƒng phÃ¢n loáº¡i nhÃ³m thiá»ƒu sá»‘, lÃ m cho mÃ´ hÃ¬nh trá»Ÿ nÃªn máº¡nh máº½ hÆ¡n, Ä‘áº·c biá»‡t phÃ¹ há»£p vá»›i cÃ¡c bÃ i toÃ¡n nhÆ° dá»± Ä‘oÃ¡n bá»‡nh tim.

# %% [markdown]
# ## **Lá»±a chá»n Ä‘áº·c trÆ°ng (Feature Selection)**<a id='Features_Selection'></a>  
# [Contents](#Contents)

# %%
# XÃ¡c Ä‘á»‹nh biáº¿n má»¥c tiÃªu:  
target = 'heart_disease'  

# Chuyá»ƒn Ä‘á»•i biáº¿n má»¥c tiÃªu thÃ nh giÃ¡ trá»‹ sá»‘:  
df[target] = df[target].apply(lambda x: 1 if x == 'yes' else 0).astype('int')

# %%
df.head()

# %%
# XÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng cáº§n chá»n:
features = ['gender', 'race', 'general_health', 'health_care_provider', 
            'could_not_afford_to_see_doctor', 'length_of_time_since_last_routine_checkup',
            'ever_diagnosed_with_heart_attack', 'ever_diagnosed_with_a_stroke',
            'ever_told_you_had_a_depressive_disorder', 'ever_told_you_have_kidney_disease',
            'ever_told_you_had_diabetes', 'BMI', 'difficulty_walking_or_climbing_stairs',
            'physical_health_status', 'mental_health_status', 'asthma_Status',
            'smoking_status', 'binge_drinking_status', 'exercise_status_in_past_30_Days',
            'age_category', 'sleep_category', 'drinks_category']

# TÃ¡ch Ä‘áº·c trÆ°ng vÃ  biáº¿n má»¥c tiÃªu
X = df[features]
y = df[target]


# %% [markdown]
# ## **MÃ£ hÃ³a danh má»¥c vá»›i CatBoost**<a id='Categorical_Encoding_with_Catboost'></a>  
# [Contents](#Contents)  
# 
# Nhiá»u thuáº­t toÃ¡n há»c mÃ¡y yÃªu cáº§u dá»¯ liá»‡u á»Ÿ dáº¡ng sá»‘. Do Ä‘Ã³, trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh hoáº·c tÃ­nh toÃ¡n há»‡ sá»‘ tÆ°Æ¡ng quan Pearson hay thÃ´ng tin tÆ°Æ¡ng há»— (prediction power), chÃºng ta cáº§n chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u danh má»¥c thÃ nh dáº¡ng sá»‘. CÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a danh má»¥c khÃ¡c nhau, trong Ä‘Ã³ CatBoost lÃ  má»™t phÆ°Æ¡ng phÃ¡p phá»• biáº¿n.  
# 
# CatBoost lÃ  má»™t phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a danh má»¥c dá»±a trÃªn giÃ¡ trá»‹ má»¥c tiÃªu (target-based encoding). ÄÃ¢y lÃ  má»™t phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a cÃ³ giÃ¡m sÃ¡t, chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t danh má»¥c theo giÃ¡ trá»‹ cá»§a biáº¿n má»¥c tiÃªu, há»— trá»£ cáº£ biáº¿n má»¥c tiÃªu nhá»‹ phÃ¢n vÃ  liÃªn tá»¥c.  
# 
# ### **MÃ£ hÃ³a Target Encoding vÃ  váº¥n Ä‘á» rÃ² rá»‰ dá»¯ liá»‡u (Target Leakage)**  
# MÃ£ hÃ³a target encoding thay tháº¿ má»™t giÃ¡ trá»‹ danh má»¥c báº±ng giÃ¡ trá»‹ trung bÃ¬nh cá»§a biáº¿n má»¥c tiÃªu tÆ°Æ¡ng á»©ng vá»›i danh má»¥c Ä‘Ã³ trong táº­p huáº¥n luyá»‡n, káº¿t há»£p vá»›i xÃ¡c suáº¥t xuáº¥t hiá»‡n biáº¿n má»¥c tiÃªu trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u. Tuy nhiÃªn, phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ gÃ¢y ra hiá»‡n tÆ°á»£ng **rÃ² rá»‰ má»¥c tiÃªu** (target leakage) vÃ¬ giÃ¡ trá»‹ cá»§a biáº¿n má»¥c tiÃªu Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n chÃ­nh nÃ³. Äiá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n **quÃ¡ khá»›p** (overfitting), lÃ m cho mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng kÃ©m khi Ã¡p dá»¥ng vÃ o dá»¯ liá»‡u má»›i.  
# 
# ### **MÃ£ hÃ³a CatBoost vÃ  cÃ¡ch kháº¯c phá»¥c rÃ² rá»‰ dá»¯ liá»‡u**  
# MÃ£ hÃ³a CatBoost tÆ°Æ¡ng tá»± target encoding nhÆ°ng bá»• sung má»™t nguyÃªn táº¯c **thá»© tá»± quan sÃ¡t** nháº±m kháº¯c phá»¥c váº¥n Ä‘á» rÃ² rá»‰ dá»¯ liá»‡u. NÃ³ hoáº¡t Ä‘á»™ng theo nguyÃªn táº¯c giá»‘ng nhÆ° xÃ¡c thá»±c dá»¯ liá»‡u chuá»—i thá»i gian (time-series validation).  
# 
# Cá»¥ thá»ƒ, giÃ¡ trá»‹ mÃ£ hÃ³a cá»§a biáº¿n danh má»¥c Ä‘Æ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn dá»¯ liá»‡u **trÆ°á»›c Ä‘Ã³** trong táº­p dá»¯ liá»‡u. NghÄ©a lÃ , xÃ¡c suáº¥t má»¥c tiÃªu cho má»™t giÃ¡ trá»‹ danh má»¥c táº¡i má»™t dÃ²ng dá»¯ liá»‡u chá»‰ Ä‘Æ°á»£c tÃ­nh tá»« cÃ¡c dÃ²ng dá»¯ liá»‡u **Ä‘á»©ng trÆ°á»›c nÃ³**. CÃ¡ch tiáº¿p cáº­n nÃ y giÃºp háº¡n cháº¿ viá»‡c mÃ´ hÃ¬nh "nhÃ¬n tháº¥y" thÃ´ng tin trong tÆ°Æ¡ng lai, tá»« Ä‘Ã³ giáº£m thiá»ƒu kháº£ nÄƒng quÃ¡ khá»›p vÃ  cáº£i thiá»‡n tÃ­nh tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh.

# %%
# Khá»Ÿi táº¡o bá»™ mÃ£ hÃ³a CatBoost:  
cbe_encoder = ce.CatBoostEncoder()  

# Huáº¥n luyá»‡n vÃ  chuyá»ƒn Ä‘á»•i táº­p dá»¯ liá»‡u:  
cbe_encoder.fit(X, y)  

# Thay tháº¿ cÃ¡c cá»™t danh má»¥c ban Ä‘áº§u báº±ng cÃ¡c cá»™t Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a:  
X_cbe = cbe_encoder.transform(X)

# %% [markdown]
# ## **Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra**<a id='Split_data_into_training_and_testing_sets'></a>  
# [Contents](#Contents)

# %%
#train, test, split
X_train, X_test, y_train, y_test = train_test_split(X_cbe,
                                                    y,
                                                    test_size=0.20, 
                                                    random_state=1981)

# %% [markdown]
# ## **Chuáº©n hÃ³a Ä‘áº·c trÆ°ng cho Há»“i quy Logistic**<a id='Scale_features_for_Logistic_Regression'></a>  
# [Contents](#Contents)

# %%
# Chuáº©n hÃ³a Ä‘áº·c trÆ°ng cho Há»“i quy Logistic:  
scaler = StandardScaler()  
X_train_scaled = scaler.fit_transform(X_train)  
X_test_scaled = scaler.transform(X_test)

# %% [markdown]
# ## **MÃ´ hÃ¬nh CÆ¡ báº£n**<a id='Baseline_Modeling'></a>  
# [Contents](#Contents)  
# 
# Táº¡i Ä‘Ã¢y, chÃºng ta sáº½ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh dÆ°á»›i Ä‘Ã¢y vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a chÃºng trÃªn tá»«ng lá»›p cá»¥ thá»ƒ:  
# 
# * Há»“i quy Logistic (Logistic Regression)  
# * Rá»«ng ngáº«u nhiÃªn (Random Forest)  
# * XGBoost  
# * LightGBM  
# * Balanced Bagging  
# * Easy Ensemble  
# * Balanced Random Forest  
# * Balanced Bagging (LightGBM): Balanced Bagging Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m trÃ¬nh bao bá»c (wrapper) vÃ  LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ  
# * Easy Ensemble (LightGBM): Easy Ensemble Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m trÃ¬nh bao bá»c (wrapper) vÃ  LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ  

# %%
# Khá»Ÿi táº¡o cÃ¡c mÃ´ hÃ¬nh  
models = {
    'Há»“i quy Logistic': LogisticRegression(random_state=1981),
    'Rá»«ng ngáº«u nhiÃªn': RandomForestClassifier(n_jobs=-1, random_state=1981),  # Sá»­ dá»¥ng xá»­ lÃ½ song song
    'LightGBM': LGBMClassifier(n_jobs=-1, random_state=1981),
    'XGBoost': XGBClassifier(n_jobs=-1, random_state=1981, use_label_encoder=False, eval_metric='logloss'),
    'Balanced Bagging': BalancedBaggingClassifier(random_state=1981),
    'Easy Ensemble': EasyEnsembleClassifier(random_state=1981),
    'Balanced Random Forest': BalancedRandomForestClassifier(random_state=1981),
    'Balanced Bagging (LightGBM)': BalancedBaggingClassifier(estimator=LGBMClassifier(n_jobs=-1, random_state=1981), random_state=1981),
    'Easy Ensemble (LightGBM)': EasyEnsembleClassifier(estimator=LGBMClassifier(n_jobs=-1, random_state=1981), random_state=1981)
}

# %% [markdown]
# ### **So sÃ¡nh cÃ¡c chá»‰ sá»‘ theo tá»«ng lá»›p**<a id='class_specific_level_Metrics_Comparison'></a>  
# [Contents](#Contents)

# %%
# Táº¡o má»™t DataFrame Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
metrics_df = pd.DataFrame()

# Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh
for name, model in models.items():
    if name == 'Logistic Regression':
        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»“i quy logistic vá»›i dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)  # Dá»± Ä‘oÃ¡n nhÃ£n Ä‘áº§u ra
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]  # XÃ¡c suáº¥t dá»± Ä‘oÃ¡n cá»§a lá»›p dÆ°Æ¡ng (1)
    else:
        # Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c vá»›i dá»¯ liá»‡u chÆ°a chuáº©n hÃ³a
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # TÃ­nh cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
    accuracy = accuracy_score(y_test, y_pred)  # Äá»™ chÃ­nh xÃ¡c
    precision = precision_score(y_test, y_pred, average=None)  # Äá»™ chÃ­nh xÃ¡c theo tá»«ng lá»›p
    recall = recall_score(y_test, y_pred, average=None)  # Äá»™ nháº¡y theo tá»«ng lá»›p
    f1 = f1_score(y_test, y_pred, average=None)  # Chá»‰ sá»‘ F1-score theo tá»«ng lá»›p
    roc_auc = roc_auc_score(y_test, y_pred_proba)  # Äiá»ƒm ROC AUC tá»•ng thá»ƒ
    
    # ThÃªm cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ vÃ o DataFrame báº±ng cÃ¡ch sá»­ dá»¥ng pd.concat
    model_metrics = pd.DataFrame({
        'Model': [name] * len(precision),  # TÃªn mÃ´ hÃ¬nh
        'Class': list(range(len(precision))),  # NhÃ£n cá»§a tá»«ng lá»›p
        'Accuracy': [accuracy] * len(precision),  # Äá»™ chÃ­nh xÃ¡c chung cho tá»«ng lá»›p
        'Precision': precision,  # Äá»™ chÃ­nh xÃ¡c
        'Recall': recall,  # Äá»™ nháº¡y
        'F1 Score': f1,  # Chá»‰ sá»‘ F1-score
        'ROC AUC': [roc_auc] * len(precision)  # Äiá»ƒm ROC AUC chung
    })
    metrics_df = pd.concat([metrics_df, model_metrics], ignore_index=True)

# Hiá»ƒn thá»‹ DataFrame chá»©a káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cá»§a cÃ¡c mÃ´ hÃ¬nh
metrics_df


# %% [markdown]
# ### **TÃ³m táº¯t cÃ¡c chá»‰ sá»‘ theo tá»«ng lá»›p**<a id='Class_specific_level_Metrics_Summary'></a>
# [Contents](#Contents)

# %% [markdown]
# 
# * **Recall cao, Precision vÃ  F1 Score tháº¥p:**  
#   - Pháº§n lá»›n cÃ¡c mÃ´ hÃ¬nh cÃ³ recall tháº¥p Ä‘á»‘i vá»›i lá»›p 1 (bá»‡nh nhÃ¢n máº¯c bá»‡nh tim), ngoáº¡i trá»« cÃ¡c mÃ´ hÃ¬nh Balanced Bagging, Easy Ensemble, Balanced Random Forest vÃ  cÃ¡c mÃ´ hÃ¬nh nÃ y khi káº¿t há»£p vá»›i LightGBM.  
#   - Äiá»u nÃ y cho tháº¥y háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh gáº·p khÃ³ khÄƒn trong viá»‡c nháº­n diá»‡n cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh (bá»‡nh nhÃ¢n máº¯c bá»‡nh tim), dáº«n Ä‘áº¿n sá»‘ lÆ°á»£ng Ä‘Ã¡ng ká»ƒ cÃ¡c trÆ°á»ng há»£p Ã¢m tÃ­nh giáº£ (bá»‡nh nhÃ¢n máº¯c bá»‡nh tim nhÆ°ng bá»‹ phÃ¢n loáº¡i nháº§m thÃ nh khÃ´ng máº¯c bá»‡nh).  
# 
# * **Balanced Bagging vÃ  Easy Ensemble:**  
#   - CÃ¡c mÃ´ hÃ¬nh Balanced Bagging, Easy Ensemble vÃ  Balanced Random Forest Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ váº¥n Ä‘á» máº¥t cÃ¢n báº±ng lá»›p báº±ng cÃ¡ch cÃ¢n báº±ng dá»¯ liá»‡u trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.  
#   - Hiá»‡u suáº¥t:  
#     - ChÃºng Ä‘áº¡t recall cao hÆ¡n Ä‘á»‘i vá»›i lá»›p 1, tá»©c lÃ  cÃ³ kháº£ nÄƒng nháº­n diá»‡n pháº§n lá»›n cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh thá»±c sá»±.  
#     - Äá»•i láº¡i, precision thÆ°á»ng tháº¥p hÆ¡n, dáº«n Ä‘áº¿n F1 Score giáº£m.  
# 
# * **Ã nghÄ©a trong bá»‘i cáº£nh y táº¿:**  
#   - Trong lÄ©nh vá»±c y táº¿, recall cao lÃ  ráº¥t quan trá»ng vÃ¬ cáº§n phÃ¡t hiá»‡n cÃ ng nhiá»u trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh thá»±c sá»± cÃ ng tá»‘t, ngay cáº£ khi pháº£i cháº¥p nháº­n má»™t sá»‘ dÆ°Æ¡ng tÃ­nh giáº£.  
#   - Viá»‡c bá» sÃ³t má»™t bá»‡nh nhÃ¢n thá»±c sá»± máº¯c bá»‡nh tim (Ã¢m tÃ­nh giáº£) cÃ³ thá»ƒ nghiÃªm trá»ng hÆ¡n so vá»›i viá»‡c cháº©n Ä‘oÃ¡n nháº§m má»™t ngÆ°á»i khá»e máº¡nh lÃ  máº¯c bá»‡nh (dÆ°Æ¡ng tÃ­nh giáº£).  
# 
# * **Sá»­ dá»¥ng LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ:**  
#   - **Hiá»‡u suáº¥t vá»›i LightGBM:**  
#     - Khi sá»­ dá»¥ng LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ trong Balanced Bagging vÃ  Easy Ensemble, recall cá»§a lá»›p 1 Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ.  
#     - CÃ¡c mÃ´ hÃ¬nh nÃ y cÅ©ng cÃ³ Ä‘iá»ƒm ROC AUC tá»‘t hÆ¡n (0.885894 vÃ  0.885778), cho tháº¥y sá»± cÃ¢n báº±ng tá»‘t giá»¯a Ä‘á»™ nháº¡y (sensitivity) vÃ  Ä‘á»™ Ä‘áº·c hiá»‡u (specificity).  
#     - LightGBM lÃ  má»™t thuáº­t toÃ¡n boosting máº¡nh máº½, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i hiá»‡u suáº¥t cao vÃ  kháº£ nÄƒng tá»‘i Æ°u hÃ³a tá»‘t, giÃºp cáº£i thiá»‡n cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ tá»•ng thá»ƒ.  
#   - **Cáº£i thiá»‡n:**  
#     - Khi sá»­ dá»¥ng Easy Ensemble vá»›i LightGBM, recall cho lá»›p 1 (bá»‡nh nhÃ¢n máº¯c bá»‡nh tim) tÄƒng Ä‘Ã¡ng ká»ƒ tá»« 24.4% (khi dÃ¹ng LightGBM riÃªng láº») lÃªn 80.7%.  
#     - ROC AUC cÅ©ng tÄƒng tá»« 88.4% lÃªn 88.6%, cho tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng cÃ¢n báº±ng tá»‘t giá»¯a viá»‡c nháº­n diá»‡n Ä‘Ãºng cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh thá»±c sá»± vÃ  giáº£m thiá»ƒu dÆ°Æ¡ng tÃ­nh giáº£.  
# 
# * **á»¨ng dá»¥ng thá»±c tiá»…n: Nhiá»‡m vá»¥ phÃ¢n loáº¡i bá»‡nh tim:**  
#   - Viá»‡c xÃ¡c Ä‘á»‹nh Ä‘Ãºng bá»‡nh nhÃ¢n máº¯c bá»‡nh tim (dÆ°Æ¡ng tÃ­nh thá»±c sá»±) lÃ  cá»±c ká»³ quan trá»ng.  
#   - Recall cao thÆ°á»ng Ä‘Æ°á»£c Æ°u tiÃªn hÆ¡n, ngay cáº£ khi pháº£i cháº¥p nháº­n nhiá»u dÆ°Æ¡ng tÃ­nh giáº£ hÆ¡n.  
#   - Recall cao Ä‘áº£m báº£o háº§u háº¿t cÃ¡c bá»‡nh nhÃ¢n máº¯c bá»‡nh tim Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh, giÃºp can thiá»‡p vÃ  Ä‘iá»u trá»‹ sá»›m.  
#   - DÆ°Æ¡ng tÃ­nh giáº£, máº·c dÃ¹ khÃ´ng lÃ½ tÆ°á»Ÿng, nhÆ°ng cÃ³ thá»ƒ Ä‘Æ°á»£c xá»­ lÃ½ báº±ng cÃ¡c xÃ©t nghiá»‡m bá»• sung vÃ  Ä‘Ã¡nh giÃ¡ y táº¿ chi tiáº¿t hÆ¡n.  
# 
# * **Káº¿t luáº­n:**  
#   - CÃ¡c mÃ´ hÃ¬nh Balanced Bagging, Easy Ensemble vÃ  Balanced Random Forest, Ä‘áº·c biá»‡t khi káº¿t há»£p vá»›i LightGBM lÃ m bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ, cung cáº¥p sá»± cÃ¢n báº±ng tá»‘t giá»¯a viá»‡c xÃ¡c Ä‘á»‹nh Ä‘Ãºng cÃ¡c trÆ°á»ng há»£p máº¯c bá»‡nh tim vÃ  duy trÃ¬ tá»· lá»‡ dÆ°Æ¡ng tÃ­nh giáº£ á»Ÿ má»©c há»£p lÃ½.  
#   - Äá»‘i vá»›i má»™t á»©ng dá»¥ng y táº¿ nhÆ° dá»± Ä‘oÃ¡n bá»‡nh tim, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y giÃºp phÃ¡t hiá»‡n háº§u háº¿t cÃ¡c trÆ°á»ng há»£p máº¯c bá»‡nh, cho phÃ©p can thiá»‡p y táº¿ ká»‹p thá»i, Ä‘iá»u nÃ y ráº¥t quan trá»ng Ä‘á»‘i vá»›i sá»©c khá»e bá»‡nh nhÃ¢n.  
# 
# 

# %% [markdown]
# ## **Lá»±a chá»n mÃ´ hÃ¬nh**<a id='Model_Selection'></a>  
# [Contents](#Contents)  
# 
# * Dá»±a trÃªn cÃ¡c chá»‰ sá»‘ trÃªn, **mÃ´ hÃ¬nh Easy Ensemble (LightGBM)** lÃ  lá»±a chá»n tá»‘t nháº¥t lÃ m mÃ´ hÃ¬nh cuá»‘i cÃ¹ng:  
#     * Äá»™ chÃ­nh xÃ¡c (Accuracy): `0.793546`  
#     * Äá»™ chÃ­nh xÃ¡c theo lá»›p (Precision): `0.201685`  
#     * Äá»™ nháº¡y (Recall): `0.807671`  
#     * Äiá»ƒm F1 (F1 Score): `0.322771`  
#     * Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC (ROC AUC): `0.885778`  
# 
# * **Táº¡i sao chá»n Easy Ensemble (LightGBM)?**  
#     * **Äá»™ nháº¡y cao `(0.807671)`**: Äáº£m báº£o xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c pháº§n lá»›n cÃ¡c trÆ°á»ng há»£p dÆ°Æ¡ng tÃ­nh thá»±c sá»± (bá»‡nh nhÃ¢n máº¯c bá»‡nh tim).  
#     * **Chá»‰ sá»‘ ROC AUC tá»‘t `(0.885778)`**: Cho tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t giá»¯a cÃ¡c lá»›p.  
#     * **Xá»­ lÃ½ tá»‘t váº¥n Ä‘á» máº¥t cÃ¢n báº±ng lá»›p**: Easy Ensemble giÃºp cÃ¢n báº±ng dá»¯ liá»‡u, má»™t thÃ¡ch thá»©c phá»• biáº¿n trong cÃ¡c bá»™ dá»¯ liá»‡u y táº¿.

# %% [markdown]
# ## **Äiá»u chá»‰nh siÃªu tham sá»‘ báº±ng Optuna**<a id='Hyperparameter_Tuning_using_Optuna'></a>  
# [Contents](#Contents)

# %%
import time  # ThÆ° viá»‡n Ä‘á»ƒ Ä‘o thá»i gian thá»±c thi
import warnings  # ThÆ° viá»‡n Ä‘á»ƒ áº©n cáº£nh bÃ¡o
import optuna
import lightgbm as lgb
import logging
from sklearn.model_selection import cross_val_score
from imblearn.ensemble import EasyEnsembleClassifier
from lightgbm import LGBMClassifier

# áº¨n táº¥t cáº£ cáº£nh bÃ¡o
warnings.filterwarnings("ignore")

# Cáº¥u hÃ¬nh logging Ä‘á»ƒ áº©n cÃ¡c thÃ´ng bÃ¡o dÆ°á»›i má»©c WARNING
logging.basicConfig(level=logging.CRITICAL)

start = time.time()  # Ghi nháº­n thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u tá»‘i Æ°u hÃ³a

def objective(trial):
    """
    HÃ m má»¥c tiÃªu Ä‘á»ƒ Optuna tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cho mÃ´ hÃ¬nh Easy Ensemble (LightGBM).
    """

    # XÃ¡c Ä‘á»‹nh khÃ´ng gian tÃ¬m kiáº¿m siÃªu tham sá»‘:
    params = {
        'n_estimators': trial.suggest_categorical('n_estimators', [10, 50, 100, 500, 1000, 5000]),  # Sá»‘ lÆ°á»£ng cÃ¢y
        'learning_rate': trial.suggest_categorical('learning_rate', [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]),  # Tá»‘c Ä‘á»™ há»c
        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),  # Loáº¡i boosting
        'num_leaves': trial.suggest_int('num_leaves', 2, 256),  # Sá»‘ lÃ¡ cá»§a má»—i cÃ¢y
        'max_depth': trial.suggest_int('max_depth', 3, 30),  # Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a cÃ¢y
        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),  # Sá»‘ máº«u tá»‘i thiá»ƒu trong má»™t lÃ¡
        'subsample': trial.suggest_float('subsample', 0.1, 1.0),  # Tá»· lá»‡ láº¥y máº«u ngáº«u nhiÃªn cá»§a dá»¯ liá»‡u
        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.6, 0.7, 0.8, 0.9]),  # Tá»· lá»‡ láº¥y máº«u cá»™t (features)
        'reg_alpha': trial.suggest_categorical('reg_alpha', [0, 0.2, 0.4, 0.6, 0.8, 1]),  # Há»‡ sá»‘ pháº¡t L1 (Lasso)
        'reg_lambda': trial.suggest_categorical('reg_lambda', [0, 0.2, 0.4, 0.6, 0.8, 1])  # Há»‡ sá»‘ pháº¡t L2 (Ridge)
    }

    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh Easy Ensemble vá»›i LGBMClassifier lÃ m estimator:
    model = EasyEnsembleClassifier(
        estimator=LGBMClassifier(**params, n_jobs=-1, random_state=1981),  # Sá»­ dá»¥ng táº¥t cáº£ lÃµi CPU
        random_state=1981  # Äáº£m báº£o káº¿t quáº£ cÃ³ thá»ƒ tÃ¡i láº­p
    )

    # Thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng cross-validation (CV = 3) vÃ  tÃ­nh Ä‘iá»ƒm Recall trung bÃ¬nh:
    score = cross_val_score(model, X_train, y_train, scoring='recall', cv=3).mean()
    return score  # Tráº£ vá» giÃ¡ trá»‹ Recall Ä‘á»ƒ Optuna tá»‘i Æ°u hÃ³a

# Táº¡o má»™t Ä‘á»‘i tÆ°á»£ng study Ä‘á»ƒ tÃ¬m kiáº¿m siÃªu tham sá»‘ tá»‘t nháº¥t, vá»›i má»¥c tiÃªu tá»‘i Ä‘a hÃ³a Recall:
study = optuna.create_study(direction='maximize')

# Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh tá»‘i Æ°u vá»›i 5 láº§n thá»­ nghiá»‡m (n_trials=5):
study.optimize(objective, n_trials=5)

# Ghi nháº­n thá»i gian káº¿t thÃºc:
end = time.time()
duration = end - start  # TÃ­nh tá»•ng thá»i gian thá»±c hiá»‡n

# In ra thá»i gian tá»‘i Æ°u hÃ³a:
print('\nTá»‘i Æ°u hÃ³a tham sá»‘ máº¥t %0.2f giÃ¢y (%0.1f phÃºt)' % (duration, duration / 60))

# In ra siÃªu tham sá»‘ tá»‘t nháº¥t:
print("\nSiÃªu tham sá»‘ tá»‘i Æ°u:\n", study.best_params)


# %% [markdown]
# ## **Huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»‘t nháº¥t (Ä‘Ã£ tinh chá»‰nh)**<a id='Fitting_Best_Model_tuned'></a>
# [Contents](#Contents)

# %%
# Láº¥y siÃªu tham sá»‘ tá»‘t nháº¥t tá»« quÃ¡ trÃ¬nh tá»‘i Æ°u
best_params = study.best_params

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh vá»›i siÃªu tham sá»‘ tá»‘i Æ°u
best_model = EasyEnsembleClassifier(
    estimator=LGBMClassifier(**best_params, n_jobs=-1, random_state=1981),
    random_state=1981
)

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n
best_model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
accuracy = accuracy_score(y_test, y_pred)  # Äá»™ chÃ­nh xÃ¡c
precision = precision_score(y_test, y_pred, average=None)  # Äá»™ chÃ­nh xÃ¡c theo tá»«ng lá»›p
recall = recall_score(y_test, y_pred, average=None)  # Äá»™ nháº¡y theo tá»«ng lá»›p
f1 = f1_score(y_test, y_pred, average=None)  # Äiá»ƒm F1 theo tá»«ng lá»›p
roc_auc = roc_auc_score(y_test, y_pred_proba)  # Äiá»ƒm ROC AUC

# Táº¡o DataFrame Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
metrics_df = pd.DataFrame()

# GhÃ©p cÃ¡c chá»‰ sá»‘ vÃ o DataFrame báº±ng pd.concat
model_metrics = pd.DataFrame({
    'Model': ['Easy Ensemble (LightGBM)'] * len(precision),
    'Class': list(range(len(precision))),  # NhÃ£n lá»›p
    'Accuracy': [accuracy] * len(precision),
    'Precision': precision,
    'Recall': recall,
    'F1 Score': f1,
    'ROC AUC': [roc_auc] * len(precision)
})

# Káº¿t há»£p káº¿t quáº£ vÃ o DataFrame chÃ­nh
metrics_df = pd.concat([metrics_df, model_metrics], ignore_index=True)


# %% [markdown]
# ### **TÃ³m táº¯t cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ cá»§a mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Ã£ tinh chá»‰nh:**  
# 
# #### **Lá»›p 0:**  
# - MÃ´ hÃ¬nh cÃ³ **Ä‘á»™ chÃ­nh xÃ¡c cao** `(0.984788)` cho lá»›p 0, nghÄ©a lÃ  khi dá»± Ä‘oÃ¡n lÃ  lá»›p 0, mÃ´ hÃ¬nh Ä‘Ãºng **98.48%**.  
# - **Äá»™ nháº¡y** cá»§a lá»›p 0 cÅ©ng khÃ¡ cao `(0.785166)`, nghÄ©a lÃ  mÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh Ä‘Ãºng **78.52%** sá»‘ lÆ°á»£ng máº«u thá»±c táº¿ thuá»™c lá»›p 0.  
# - **Äiá»ƒm F1** `(0.873720)` cho tháº¥y sá»± cÃ¢n báº±ng tá»‘t giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ nháº¡y.  
# - **Äiá»ƒm ROC AUC** cho lá»›p 0 lÃ  `0.785166`, thá»ƒ hiá»‡n kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t.  
# 
# #### **Lá»›p 1:**  
# - **Äá»™ chÃ­nh xÃ¡c tháº¥p** `(0.197094)`, nghÄ©a lÃ  nhiá»u dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh cho lá»›p 1 thá»±c táº¿ láº¡i thuá»™c lá»›p 0.  
# - **Äá»™ nháº¡y cao** `(0.813019)`, thá»ƒ hiá»‡n mÃ´ hÃ¬nh phÃ¡t hiá»‡n tá»‘t cÃ¡c máº«u thuá»™c lá»›p 1.  
# - **Äiá»ƒm F1** `(0.317274)` cho tháº¥y cÃ³ sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ nháº¡y.  
# - **Äiá»ƒm ROC AUC** cá»§a lá»›p 1 lÃ  `0.883942`, cho tháº¥y hiá»‡u suáº¥t tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh váº«n tá»‘t trong viá»‡c phÃ¢n biá»‡t hai lá»›p.  
# 
# ---
# 
# ### **So sÃ¡nh vá»›i mÃ´ hÃ¬nh riÃªng láº» vÃ  mÃ´ hÃ¬nh káº¿t há»£p:**  
# 
# #### **LightGBM Ä‘Æ¡n thuáº§n:**  
# - LightGBM thÆ°á»ng cÃ³ hiá»‡u suáº¥t máº¡nh nhá» ká»¹ thuáº­t boosting theo gradient.  
# - MÃ´ hÃ¬nh Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nhÆ°ng cÃ³ thá»ƒ gáº·p khÃ³ khÄƒn vá»›i **sá»± máº¥t cÃ¢n báº±ng dá»¯ liá»‡u**, khiáº¿n **Ä‘á»™ nháº¡y cá»§a lá»›p 1 tháº¥p** (vÃ­ dá»¥: Recall `24.4%`).  
# 
# #### **EasyEnsemble Ä‘Æ¡n thuáº§n:**  
# - EasyEnsemble táº­p trung vÃ o **cÃ¢n báº±ng dá»¯ liá»‡u** báº±ng cÃ¡ch **láº¥y máº«u láº¡i** vÃ  táº¡o nhiá»u mÃ´ hÃ¬nh nhá».  
# - CÃ¡ch tiáº¿p cáº­n nÃ y cáº£i thiá»‡n Ä‘á»™ nháº¡y cá»§a **lá»›p thiá»ƒu sá»‘ (lá»›p 1)** nhÆ°ng cÃ³ thá»ƒ **khÃ´ng Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nhÆ° LightGBM**.  
# - Káº¿t há»£p vá»›i LightGBM cÃ³ thá»ƒ táº­n dá»¥ng Ä‘Æ°á»£c cáº£ hai Æ°u Ä‘iá»ƒm, giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ nháº¡y.  
# 
# #### **MÃ´ hÃ¬nh káº¿t há»£p (Ä‘Ã£ tinh chá»‰nh):**  
# - Khi káº¿t há»£p **EasyEnsemble + LightGBM**, mÃ´ hÃ¬nh **cÃ¢n báº±ng tá»‘t hÆ¡n** giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ nháº¡y.  
# - Äá»™ nháº¡y cá»§a lá»›p 1 **tÄƒng tá»« `24.4%` lÃªn `81.3%`**, giÃºp nháº­n diá»‡n cÃ¡c máº«u thuá»™c lá»›p 1 tá»‘t hÆ¡n.  
# - MÃ´ hÃ¬nh váº«n duy trÃ¬ **Ä‘á»™ chÃ­nh xÃ¡c cao cho lá»›p 0 (`0.984788`)**, khÃ´ng lÃ m giáº£m hiá»‡u suáº¥t tá»•ng thá»ƒ.  
# - Äiá»ƒm ROC AUC cao (`0.883942`), chá»©ng tá» mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t phÃ¢n loáº¡i tá»•ng thá»ƒ tá»‘t.  
# 
# ---
# 
# ### **Káº¿t luáº­n:**  
# Viá»‡c sá»­ dá»¥ng **EasyEnsemble káº¿t há»£p vá»›i LightGBM** vÃ  tinh chá»‰nh siÃªu tham sá»‘ giÃºp **giáº£i quyáº¿t váº¥n Ä‘á» máº¥t cÃ¢n báº±ng dá»¯ liá»‡u**. MÃ´ hÃ¬nh Ä‘áº¡t **Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ nháº¡y cao cho lá»›p 0** vÃ  Ä‘á»“ng thá»i **cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ nháº¡y cá»§a lá»›p 1**. Tuy nhiÃªn, **Ä‘á»™ chÃ­nh xÃ¡c cá»§a lá»›p 1 váº«n lÃ  má»™t thÃ¡ch thá»©c**, cÃ³ thá»ƒ cáº§n thÃªm cÃ¡c phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u khÃ¡c nhÆ° Ä‘iá»u chá»‰nh trá»ng sá»‘ máº«u hoáº·c thÃªm dá»¯ liá»‡u huáº¥n luyá»‡n.

# %% [markdown]
# ##  **Táº§m quan trá»ng cá»§a Ä‘áº·c trÆ°ng trong mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Ã£ tinh chá»‰nh báº±ng SHAP**<a id='Tuned_Best_Model_Features_Importance_using_SHAP'></a>
# [Contents](#Contents)

# %%
# Truy cáº­p má»™t trong cÃ¡c bá»™ Æ°á»›c lÆ°á»£ng cÆ¡ sá»Ÿ Ä‘á»ƒ phÃ¢n tÃ­ch SHAP  
lgbm_model = best_model.estimators_[0].steps[-1][1]  

# Táº¡o má»™t bá»™ giáº£i thÃ­ch SHAP cho LGBMClassifier  
explainer = shap.TreeExplainer(lgbm_model)  

# TÃ­nh toÃ¡n giÃ¡ trá»‹ SHAP cho táº­p kiá»ƒm tra  
shap_values = explainer.shap_values(X_test)  

# Kiá»ƒm tra xem shap_values cÃ³ pháº£i lÃ  má»™t danh sÃ¡ch vá»›i nhiá»u lá»›p hay khÃ´ng
if isinstance(shap_values, list):  # Kiá»ƒm tra náº¿u lÃ  danh sÃ¡ch
    shap_values_class_1 = shap_values[1]  # Lá»›p 1, giáº£ sá»­ Ä‘Ã¢y lÃ  lá»›p bá»‡nh tim
else:
    shap_values_class_1 = shap_values  # Náº¿u chá»‰ cÃ³ má»™t lá»›p

# Váº½ biá»ƒu Ä‘á»“ tá»•ng quan vá» táº§m quan trá»ng cá»§a Ä‘áº·c trÆ°ng Ä‘á»‘i vá»›i bá»‡nh tim (lá»›p 1):  
shap.summary_plot(shap_values_class_1, X_test, plot_size=(6,8), show=False)


# %% [markdown]
# ### **TÃ³m táº¯t Biá»ƒu Ä‘á»“ SHAP Summary Plot cho Lá»›p 1 (Bá»‡nh nhÃ¢n máº¯c bá»‡nh tim):**  
# 
# Biá»ƒu Ä‘á»“ SHAP trÃªn thá»ƒ hiá»‡n tÃ¡c Ä‘á»™ng cá»§a tá»«ng Ä‘áº·c trÆ°ng (feature) Ä‘áº¿n dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh vá» nguy cÆ¡ máº¯c bá»‡nh tim (**class 1**). Má»—i dáº¥u cháº¥m trong biá»ƒu Ä‘á»“ Ä‘áº¡i diá»‡n cho má»™t giÃ¡ trá»‹ SHAP cá»§a má»™t Ä‘áº·c trÆ°ng, vá»›i mÃ u sáº¯c cho biáº¿t giÃ¡ trá»‹ cá»§a Ä‘áº·c trÆ°ng (Ä‘á» lÃ  giÃ¡ trá»‹ cao, xanh lÃ  giÃ¡ trá»‹ tháº¥p). DÆ°á»›i Ä‘Ã¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t:
# 
# ### **ğŸ”¹ áº¢nh hÆ°á»Ÿng DÆ°Æ¡ng Cao (TÄƒng nguy cÆ¡ máº¯c bá»‡nh tim):**  
# - **NhÃ³m tuá»•i cao:** Nhá»¯ng ngÆ°á»i lá»›n tuá»•i (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n. Tuá»•i tÃ¡c lÃ  má»™t yáº¿u tá»‘ rá»§i ro quan trá»ng Ä‘á»‘i vá»›i bá»‡nh tim.  
# - **Tiá»n sá»­ tá»«ng bá»‹ Ä‘au tim:** NgÆ°á»i tá»«ng bá»‹ Ä‘au tim (dáº¥u cháº¥m Ä‘á») cÃ³ kháº£ nÄƒng máº¯c bá»‡nh tim cao hÆ¡n, do bá»‡nh lÃ½ tim máº¡ch thÆ°á»ng cÃ³ xu hÆ°á»›ng tÃ¡i phÃ¡t.  
# 
# ### **ğŸ”¹ áº¢nh hÆ°á»Ÿng DÆ°Æ¡ng Trung BÃ¬nh:**  
# - **TÃ¬nh tráº¡ng sá»©c khá»e tá»•ng quÃ¡t:** Sá»©c khá»e kÃ©m (dáº¥u cháº¥m Ä‘á») lÃ m tÄƒng nguy cÆ¡ máº¯c bá»‡nh tim. Nhá»¯ng ngÆ°á»i cÃ³ sá»©c khá»e yáº¿u thÆ°á»ng cÃ³ nguy cÆ¡ cao hÆ¡n.  
# - **Tá»«ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n tiá»ƒu Ä‘Æ°á»ng:** NgÆ°á»i tá»«ng Ä‘Æ°á»£c bÃ¡c sÄ© cháº©n Ä‘oÃ¡n tiá»ƒu Ä‘Æ°á»ng (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n. Tiá»ƒu Ä‘Æ°á»ng lÃ  yáº¿u tá»‘ nguy cÆ¡ lá»›n Ä‘á»‘i vá»›i bá»‡nh tim máº¡ch.  
# - **Giá»›i tÃ­nh:** Má»™t sá»‘ yáº¿u tá»‘ liÃªn quan Ä‘áº¿n giá»›i tÃ­nh (cÃ³ thá»ƒ lÃ  nam giá»›i, dáº¥u cháº¥m Ä‘á») lÃ m tÄƒng nguy cÆ¡ máº¯c bá»‡nh tim. Nam giá»›i thÆ°á»ng cÃ³ nguy cÆ¡ cao hÆ¡n so vá»›i ná»¯ giá»›i á»Ÿ Ä‘á»™ tuá»•i trung niÃªn.  
# - **KhÃ³ Ä‘i láº¡i hoáº·c leo cáº§u thang:** Nhá»¯ng ngÆ°á»i gáº·p khÃ³ khÄƒn khi Ä‘i láº¡i (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n, do cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n cÃ¡c váº¥n Ä‘á» tim máº¡ch tiá»m áº©n.  
# - **Tá»«ng bá»‹ Ä‘á»™t quá»µ:** Tiá»n sá»­ Ä‘á»™t quá»µ (dáº¥u cháº¥m Ä‘á») lÃ m tÄƒng nguy cÆ¡ máº¯c bá»‡nh tim, vÃ¬ hai bá»‡nh nÃ y cÃ³ nhiá»u yáº¿u tá»‘ nguy cÆ¡ chung.  
# - **TÃ¬nh tráº¡ng hÃºt thuá»‘c:** NgÆ°á»i hÃºt thuá»‘c lÃ¡ (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n. HÃºt thuá»‘c lÃ  má»™t trong nhá»¯ng yáº¿u tá»‘ nguy cÆ¡ hÃ ng Ä‘áº§u cá»§a bá»‡nh tim máº¡ch.  
# - **Chá»‰ sá»‘ BMI cao:** NgÆ°á»i cÃ³ chá»‰ sá»‘ BMI cao (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n. BÃ©o phÃ¬ cÃ³ má»‘i liÃªn há»‡ cháº·t cháº½ vá»›i nguy cÆ¡ bá»‡nh tim.  
# - **Tá»«ng máº¯c bá»‡nh tráº§m cáº£m:** NgÆ°á»i cÃ³ tiá»n sá»­ tráº§m cáº£m (dáº¥u cháº¥m Ä‘á») cÃ³ nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n, cho tháº¥y má»‘i liÃªn há»‡ giá»¯a sá»©c khá»e tÃ¢m tháº§n vÃ  bá»‡nh tim máº¡ch.  
# - **TÃ¬nh tráº¡ng uá»‘ng rÆ°á»£u/bia:** TiÃªu thá»¥ rÆ°á»£u/bia cao (dáº¥u cháº¥m Ä‘á») cÃ³ liÃªn quan Ä‘áº¿n nguy cÆ¡ máº¯c bá»‡nh tim cao hÆ¡n. Viá»‡c láº¡m dá»¥ng rÆ°á»£u cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng tiÃªu cá»±c Ä‘áº¿n sá»©c khá»e tim máº¡ch.  
# 
# ### **ğŸ”¹ áº¢nh hÆ°á»Ÿng Há»—n Há»£p (TÃ¡c Ä‘á»™ng thay Ä‘á»•i tÃ¹y tá»«ng trÆ°á»ng há»£p):**  
# - **Chá»§ng tá»™c:** Má»™t sá»‘ yáº¿u tá»‘ chá»§ng tá»™c cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n nguy cÆ¡ máº¯c bá»‡nh tim, cho tháº¥y sá»± khÃ¡c biá»‡t vá» máº·t di truyá»n vÃ  mÃ´i trÆ°á»ng sá»‘ng.  
# - **TÃ¬nh tráº¡ng hen suyá»…n:** Má»©c Ä‘á»™ hen suyá»…n cao hÆ¡n cÃ³ thá»ƒ lÃ m tÄƒng nguy cÆ¡ máº¯c bá»‡nh tim, do áº£nh hÆ°á»Ÿng cá»§a cÃ¡c bá»‡nh hÃ´ háº¥p mÃ£n tÃ­nh Ä‘á»‘i vá»›i tim máº¡ch.  
# 
# ### **ğŸ”¹ Káº¿t luáº­n:**  
# Biá»ƒu Ä‘á»“ SHAP chá»‰ ra ráº±ng nhiá»u yáº¿u tá»‘ nhÆ° **tuá»•i tÃ¡c, tiá»n sá»­ Ä‘au tim, tÃ¬nh tráº¡ng sá»©c khá»e tá»•ng quÃ¡t, tiá»ƒu Ä‘Æ°á»ng vÃ  hÃºt thuá»‘c** cÃ³ tÃ¡c Ä‘á»™ng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n nguy cÆ¡ máº¯c bá»‡nh tim. PhÃ¢n tÃ­ch nÃ y nháº¥n máº¡nh **táº§m quan trá»ng cá»§a viá»‡c kiá»ƒm tra sá»©c khá»e Ä‘á»‹nh ká»³, kiá»ƒm soÃ¡t cÃ¡c bá»‡nh mÃ£n tÃ­nh, cÅ©ng nhÆ° chÄƒm sÃ³c sá»©c khá»e thá»ƒ cháº¥t vÃ  tinh tháº§n** Ä‘á»ƒ giáº£m thiá»ƒu nguy cÆ¡ máº¯c bá»‡nh tim. ğŸš€

# %% [markdown]
# ## **LÆ°u MÃ´ HÃ¬nh Cuá»‘i CÃ¹ng**<a id='Saving_Final_Model'></a>  
# 
# [Contents](#Contents)  
# 
# á» Ä‘Ã¢y, chÃºng ta sáº½ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t: Easy Ensemble (LightGBM) vÃ  CatBoost.

# %%
import pickle
import gzip, pickletools

# %%
# Pickling the best model:

pickle_out = open("best_model.pkl", "wb")
pickle.dump(best_model, pickle_out)
pickle_out.close()

# %%
pickle_out = open("cbe_encoder.pkl", "wb")
pickle.dump(cbe_encoder, pickle_out)
pickle_out.close()


